# Monitoring the Fleet

## Quickstart
- Ensure python is installed on your machine
- Run all of the following commands from the root:
- run `python3 -m venv venv` to set up the virtual environment
- run `source venv/bin/activate` to activate the virtual environment
- run `pip install -r requirements.txt` to install requirements
- run `uvicorn main:app --host 0.0.0.0 --port 6733` to start the app

Once the app is started, open a new terminal window and run the device simulator: `./device-simulator-linux-amd64 start` (give yourself permissions first if needed). You'll see the results in the terminal and in the `results.txt` file.


## Design choices
I chose to use python and a virtual environment (vs. docker-compose) to help me meet the timebox. (I'm happy to learn Go and configure docker on my machine in the future, but that felt ambitoius for a short code challenge).

I chose to use FastAPI because it allows for quick API setup and automatic documentation. Once the app is started, you can view the openapi.json here: `http://127.0.0.1:6733/openapi.json` (it differs slightly from the contract in the challenge docs because I'm using a different version). There is additional autogenerated documentation here: `http://127.0.0.1:6733/docs`.

I additionally used a few libraries to help with specific tasks (e.g. pandas to load the csv file).

## Testing
I used pytest for unit tests. To run the tests, navigate to the root directory and run `python3 -m pytest tests`.

To meet the timebox, I only tested the calculations used in the endpoints. If I had more time, I would additionally test the endpoints (by mocking the calculation and asserting the correct response code and shape).

## Discussion Questions
○ How long did you spend working on the problem? What did you find to be the
most difficult part?

I spent 3-3.5 hours getting the expected results, and then another 1-1.5 hours on code cleanup, testing, and documentation.

I haven't worked with IoT before, so the most difficult part was figuring out what to do with the device simulator.

○ How would you modify your data model or code to account for more kinds of
metrics?

My solution doesn't use a data model--it just stores data in a variable--so outside of a code challenge, I'd use a real database to store metrics. 

As far as code, since the challenge only asks for three relatively simple endpoints, I put them all in `main.py` file. If the complexity increased, I'd create directories so each endpoint and schema could have their own file. Additionally, I might create a service layer for calculations and database access so that the endpoints would only be responsible for calling a service function.

I'd also like to set up alerting (perhaps something like sentry or metabase alerts) to be notified or errors.

○ Discuss your solution’s runtime complexity

For the most part, my solution is O1 because I'm using lookups and simple math. Loading the device spreadsheet (loop) and `calculate_time_duration` (getting average) will get slower as the dataset gets bigger.